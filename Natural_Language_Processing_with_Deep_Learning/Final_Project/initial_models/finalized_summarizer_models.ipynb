{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "capital-clearance",
   "metadata": {},
   "source": [
    "<h1 align = \"left\"> Finalized Summarizer Models and Evaluation Metrics </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-skirt",
   "metadata": {},
   "source": [
    "<h2 align = \"left\"><em> Abstractive Summarizer and Evaluation  </em></h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "polar-force",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%capture` not found.\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "# INSTALLS #\n",
    "############\n",
    "\n",
    "%%capture\n",
    "!pip install datasets==1.0.2\n",
    "!pip install transformers==4.2.1\n",
    "!pip install rouge_score\n",
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "comic-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# IMPORTS #\n",
    "###########\n",
    "\n",
    "import datasets\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM  \n",
    "from transformers import BertTokenizer, EncoderDecoderModel\n",
    "\n",
    "from functools import reduce\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "numeric-retirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "# GLOBAL VARS #\n",
    "###############\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"patrickvonplaten/bert2bert_cnn_daily_mail\")  \n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"patrickvonplaten/bert2bert_cnn_daily_mail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faced-gregory",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset cnn_dailymail (/home/jupyter/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602)\n"
     ]
    }
   ],
   "source": [
    "########\n",
    "# DATA #\n",
    "########\n",
    "\n",
    "test_data = datasets.load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "minor-massage",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# HELPER FUNCTIONS #\n",
    "####################\n",
    "\n",
    "divString = lambda size, char = \"#\": reduce(add, [char for i in range(size)])\n",
    "flatten = lambda lst: [i for sublst in lst for i in sublst]\n",
    "\n",
    "def generate_summary(batch):\n",
    "    \"\"\"This function computes a summary for a given article from the Dataset object\n",
    "    batch\n",
    "    Params:\n",
    "    batch: an article from the given Dataset object.\"\"\"\n",
    "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
    "    # cut off at BERT max length 512\n",
    "    inputs = tokenizer(batch[\"article\"], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    input_ids = inputs.input_ids\n",
    "    attention_mask = inputs.attention_mask\n",
    "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
    "    # all special tokens including will be removed\n",
    "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    batch[\"pred\"] = output_str\n",
    "    return batch\n",
    "\n",
    "def compute_metrics(batch, batch_size=16, metric_name=\"rouge\"):\n",
    "    \"\"\"This function computes the rouge or bleu scores for predicted summaries\n",
    "    Params:\n",
    "    batch: A Dataset object which contains the articles at the specified indices\n",
    "    Use the select method for this function call. \n",
    "    Example format: Dataset.select([list of indices to select from the original dataset])\n",
    "    metric_name: The prefered evaluation metric to use\"\"\"\n",
    "    \n",
    "    metric = datasets.load_metric(metric_name)\n",
    "    results = batch.map(generate_summary, batched=True, batch_size=batch_size, remove_columns=[\"article\"])\n",
    "    summary_pred = results[\"pred\"]\n",
    "    label_ref = results[\"highlights\"]\n",
    "    if metric_name == \"rouge\":\n",
    "        output = metric.compute(predictions=summary_pred, references=label_ref, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "        print(\"\\n\" + \"ROUGE SCORE:\")\n",
    "        return output\n",
    "    else:\n",
    "        # Else compute bleu score with metric name \"sacrebleu\"\n",
    "        all_bleu_scores = []\n",
    "        for i in range(len(batch)):\n",
    "            output = metric.compute(predictions= [summary_pred[i]], references= [[label_ref[i]]])\n",
    "            all_bleu_scores.append(output)\n",
    "            print(\"\\n\\n\")\n",
    "            print(divString(100))\n",
    "            print(\"\\n\\n\" + \"Summary prediction: \" + \"\\n\\n\", summary_pred[i])\n",
    "            print(\"\\n\\n\" + \"Reference Label: \" + \"\\n\\n\", label_ref[i])\n",
    "            print(\"\\n\\n\" + \"BLEU SCORE:\" + \"\\n\\n\", output)\n",
    "            print(\"\\n\")\n",
    "        return all_bleu_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "unknown-administration",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jupyter/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/0128610a44e10f25b4af6689441c72af86205282d26399642f7db38fa7535602/cache-309f3785e634a4cc.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "Summary prediction: \n",
      "\n",
      " dr. anthony moschetto, 54, is charged with criminal solicitation, conspiracy, arson, arson. two other men - - james chmela, 43, and james kalamaras, 41 - - were named as accomplices. they pleaded not guilty in nassau county district court.\n",
      "\n",
      "\n",
      "Reference Label: \n",
      "\n",
      " A lawyer for Dr. Anthony Moschetto says the charges against him are baseless .\n",
      "Moschetto, 54, was arrested for selling drugs and weapons, prosecutors say .\n",
      "Authorities allege Moschetto hired accomplices to burn down the practice of former associate .\n",
      "\n",
      "\n",
      "BLEU SCORE:\n",
      "\n",
      " {'score': 3.5934005135957903, 'counts': [10, 2, 1, 0], 'totals': [51, 50, 49, 48], 'precisions': [19.607843137254903, 4.0, 2.0408163265306123, 1.0416666666666667], 'bp': 1.0, 'sys_len': 51, 'ref_len': 44}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "####################################################################################################\n",
      "\n",
      "\n",
      "Summary prediction: \n",
      "\n",
      " obama says he wants the average american to take away, as well as how enforceable his action plan is. he says the epa estimates that between 1970 and 2010, the act prevented 365, 000 early deaths from particulate matter alone. obama is trying to reframe the discussion around climate change as a public health issue.\n",
      "\n",
      "\n",
      "Reference Label: \n",
      "\n",
      " \"No challenge poses more of a public threat than climate change,\" the President says .\n",
      "He credits the Clean Air Act with making Americans \"a lot\" healthier .\n",
      "\n",
      "\n",
      "BLEU SCORE:\n",
      "\n",
      " {'score': 2.113706726725864, 'counts': [10, 2, 0, 0], 'totals': [61, 60, 59, 58], 'precisions': [16.39344262295082, 3.3333333333333335, 0.847457627118644, 0.43103448275862066], 'bp': 1.0, 'sys_len': 61, 'ref_len': 33}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 3.5934005135957903,\n",
       "  'counts': [10, 2, 1, 0],\n",
       "  'totals': [51, 50, 49, 48],\n",
       "  'precisions': [19.607843137254903,\n",
       "   4.0,\n",
       "   2.0408163265306123,\n",
       "   1.0416666666666667],\n",
       "  'bp': 1.0,\n",
       "  'sys_len': 51,\n",
       "  'ref_len': 44},\n",
       " {'score': 2.113706726725864,\n",
       "  'counts': [10, 2, 0, 0],\n",
       "  'totals': [61, 60, 59, 58],\n",
       "  'precisions': [16.39344262295082,\n",
       "   3.3333333333333335,\n",
       "   0.847457627118644,\n",
       "   0.43103448275862066],\n",
       "  'bp': 1.0,\n",
       "  'sys_len': 61,\n",
       "  'ref_len': 33}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate_summary(test_data[0])\n",
    "# compute_metrics(test_data.select([1,2]), metric_name = \"rouge\")\n",
    "compute_metrics(test_data.select([1, 2]), metric_name = \"sacrebleu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-marks",
   "metadata": {},
   "source": [
    "<h2 align = \"left\"><em> Extractive Summarizer and Evaluation  </em></h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-spice",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
